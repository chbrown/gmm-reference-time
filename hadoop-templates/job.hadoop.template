#!/bin/bash
#
#-----------------------------------------------------------------------------
# This Longhorn job script is designed to create a vnc session on 
# visualization nodes through the SGE batch system. Once the job
# is scheduled, check the output of your job (which by default is
# stored in your home directory in a file named vncserver.out)
# and it will tell you the port number that has been setup for you so
# that you can attach via a separate VNC client to the longhorn login 
# node (login1.longhorn.tacc.utexas.edu).
#
# Note that for security, we recommend setting up a tunneled VNC
# session in order to connect via a client (more information on doing
# this is available at the User Guide link below).  Once you connect,
# you should see a single xterm running which you can use to launch
# any X application (eg. Paraview or VisIt) 
#
# Note: you can fine tune the SGE submission variables below as
# needed.  Typical items to change are the runtime limit, location of
# the job output, and the allocation project to submit against (it is
# commented out for now, but is required if you have multiple
# allocations).  
#
# To submit the job, issue: "qsub /share/tacc_scripts/job.vnc" 
#
# For more information, please consult the User Guide at: 
#
# http://services.tacc.utexas.edu/index.php/longhorn-user-guide
#-----------------------------------------------------------------------------
#
#$ -V                             	# Inherit the submission environment
#$ -cwd                           	# Start job in submission dir
#$ -N HadoopJob		 	        # Job name
#$ -j y                           	# Combine stderr and stdout into stdout
#$ -o $HOME/$JOB_NAME.out      	        # Name of the output file
#$ -pe 1way 40	                  	# Request 1 vis node
#$ -q hadoop                         	# Queue name
#$ -P data
#$ -l h_rt=6:00:00                	# runtime (hh:mm:ss) - 4 hours
#$ -A TeXIT

#--------------------------------------------------------------------------
# ---- You normally should not need to edit anything below this point -----
#--------------------------------------------------------------------------

echo job $JOB_ID execution at: `date`

# our node name
NODE_HOSTNAME=`hostname -s`
echo "running on node $NODE_HOSTNAME"

# VNC server executable
VNCSERVER_BIN=`which vncserver`
echo "using default VNC server $VNCSERVER_BIN"

# set memory limits to 95% of total memory to prevent node death
NODE_MEMORY=`free -k | grep ^Mem: | awk '{ print $2; }'`
NODE_MEMORY_LIMIT=`echo "0.95 * $NODE_MEMORY / 1" | bc`
ulimit -v $NODE_MEMORY_LIMIT -m $NODE_MEMORY_LIMIT
echo "memory limit set to $NODE_MEMORY_LIMIT kilobytes"

# set wayness, used for ibrun
WAYNESS=`echo $PE | perl -pe 's/([0-9]+)way/\1/;'`
echo "set wayness to $WAYNESS"

# Check whether a vncpasswd file exists.  If not, complain and exit.
if [ \! -e $HOME/.vnc/passwd ] ; then
	echo 
	echo "=================================================================="
	echo "   You must run 'vncpasswd' once before launching a vnc session"
	echo "=================================================================="
	echo
	exit 1
fi

# launch VNC session
VNC_DISPLAY=`$VNCSERVER_BIN $@ 2>&1 | grep desktop | awk -F: '{print $2}'`
echo "got VNC display :$VNC_DISPLAY"

# todo: make sure this is a valid display, and that it is 1 or 2, since those are the only displays forwarded
# using our iptables scripts

if [ x$VNC_DISPLAY == "x" ]; then
    echo 
    echo "===================================================="
    echo "   Error launching vncserver: $VNCSERVER"
    echo "   Please submit a ticket to the TACC User Portal"
    echo "   http://portal.tacc.utexas.edu/"
    echo "===================================================="
    echo
    exit 1
fi

LOCAL_VNC_PORT=`expr 5900 + $VNC_DISPLAY`
echo "local (compute node) VNC port is $LOCAL_VNC_PORT"

LOGIN_VNC_PORT="$VNC_DISPLAY`echo $NODE_HOSTNAME | perl -ne 'print $1.$2 if /c\d(\d\d)-\d(\d\d)/;'`"
echo "got login node VNC port $LOGIN_VNC_PORT"

echo "Your VNC server is now running!"
echo "To connect via VNC client:  SSH tunnel port $LOGIN_VNC_PORT to login1.longhorn.tacc.utexas.edu:$LOGIN_VNC_PORT"
echo "                            Then connect to localhost::$LOGIN_VNC_PORT"
#echo
#echo "OR:                         Connect directly to login1.longhorn.tacc.utexas.edu::$LOGIN_VNC_PORT"
#echo

# set display for X applications
export DISPLAY=":$VNC_DISPLAY"


# Warn the user when their session is about to close
# see if the user set their own runtime
TACC_RUNTIME=`qstat -j $JOB_ID | grep h_rt | perl -ne 'print $1 if /h_rt=(\d+)/'`  # qstat returns seconds
if [ x"$TACC_RUNTIME" == "x" ]; then
	TACC_LIMITS=/share/sge6.2/default/tacc/sge_job_filter_control
	TACC_Q_RUNTIME=`grep vis $TACC_LIMITS | grep max_time_per_job | cut -d' ' -f4`
	if [ x"$TACC_Q_RUNTIME" != "x" ]; then
		# pnav: this assumes format hh:dd:ss and converts to seconds
		#       if days are specified, this won't work
		TACC_RUNTIME=$TACC_Q_RUNTIME
	fi
fi
if [ x"$TACC_RUNTIME" != "x" ]; then
	# there's a runtime limit, so warn the user when the session will die
	# give 5 minute warning for runtimes > 5 minutes
	if [ $TACC_RUNTIME -gt 300 ]; then
		TACC_RUNTIME=`expr $TACC_RUNTIME - 300`
		sleep $TACC_RUNTIME && echo "$USER's VNC session on $VNC_DISPLAY will end in 5 minutes.  Please save your work now." | wall &
	fi
fi

# we need vglclient to run to have graphics across multi-node jobs
vglclient >& /dev/null &
VGL_PID=$!

export HADOOP_HOME=${HOME}/hadoop
export JAVA_HOME=/share/apps/teragrid/jdk1.6.0_19-64bit/
export PATH=$HADOOP_HOME/bin:${PATH}

start-cluster.sh
firefox "http://localhost:50070/" "http://localhost:50030/" &

# run an xterm for the user; execution will hold here

xterm -r -ls -geometry 80x24+10+10 -title '*** Exit this window to kill your VNC server ***'

# job is done!
stop-cluster.sh

echo "Killing VGL client"
kill $VGL_PID

echo "Killing VNC server" 
vncserver -kill $DISPLAY

# wait a brief moment so vncserver can clean up after itself
sleep 1

echo job $JOB_ID execution finished at: `date`
