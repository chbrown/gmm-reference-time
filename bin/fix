#!/bin/bash

stop-all.sh
export HADOOP_CONF_DIR=${HOME}/.hadoop2/conf/
#the following will delete everthing user created in /hadoop /tmp during the job. 
username=`whoami`
for line in `cat ${HADOOP_CONF_DIR}/slaves`;
do
echo $line
ssh -Y $line "rm -rf /hadoop/$username"
done
rm -rf /hadoop/$username


export HADOOP_CONF_DIR=${HOME}/.hadoop2/conf/
export HADOOP_HOME=${HOME}/hadoop

if [ ! -d ${HOME}/.hadoop2 ]; then 
mkdir -p ${HOME}/.hadoop2
fi

if [ ! -d ${HADOOP_CONF_DIR} ]; then 
mkdir -p ${HADOOP_CONF_DIR}
#cp ${HADOOP_HOME}/conf/* ${HADOOP_CONF_DIR}
cp ${HADOOP_HOME}/share/hadoop/common/templates/conf/* ${HADOOP_CONF_DIR}
cp ${HADOOP_CONF_DIR}hdfs-site.xml.default ${HADOOP_CONF_DIR}hdfs-site.xml
fi


namenode=`hostname -a`
jobnode=$namenode
username=`whoami`
sed -e "s|localhost|$jobnode|g" ${HADOOP_CONF_DIR}mapred-site.xml.default | sed -e "s|username|$username|g" > ${HADOOP_CONF_DIR}mapred-site.xml
sed -e "s|localhost|$namenode|g" ${HADOOP_CONF_DIR}core-site.xml.default | sed -e "s|username|$username|g" > ${HADOOP_CONF_DIR}core-site.xml
sed -e "s|localhost|$namenode|g" ${HADOOP_CONF_DIR}hdfs-site.xml.default | sed -e "s|username|$username|g" > ${HADOOP_CONF_DIR}hdfs-site.xml

#${HADOOP_HOME}/bin/hadoop namenode -format
hadoop namenode -format
#${HADOOP_HOME}/bin/start-all.sh
start-all.sh

